# paper_agent/llm/llm_interface.py

from typing import Dict, Any, Optional
from utils.logger import logger
from utils.config import config
import json


class LLMInterface:
    """
    A placeholder class to interact with Large Language Models (LLMs).
    In a real implementation, this would connect to OpenAI, Anthropic,
    HuggingFace, or a local LLM via their respective APIs.
    """

    def __init__(self):
        self.api_key = config.get("LLM_API_KEY")
        self.model_name = config.get("LLM_MODEL_NAME")
        if self.api_key == "YOUR_OPENAI_API_KEY_OR_OTHER_LLM_KEY":
            logger.warning("LLM_API_KEY is not set in config.json. LLM calls will be simulated.")
            self.simulate_mode = True
        else:
            self.simulate_mode = False
            # In a real scenario, initialize the LLM client here
            # e.g., self.client = OpenAI(api_key=self.api_key)
            logger.info(f"LLMInterface initialized with model: {self.model_name}")

    def generate_text(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.7) -> Optional[str]:
        """
        Generates text using the configured LLM.
        For now, it simulates a response if API key is not set.
        """
        if self.simulate_mode:
            logger.info(f"Simulating LLM response for prompt (first 100 chars): {prompt[:100]}...")
            # Simple keyword-based simulation for testing
            if "extract metadata" in prompt.lower() and "json" in prompt.lower():
                return json.dumps(
                    {
                        "title": "Simulated Paper Title from LLM",
                        "authors": "Simulated Author One, Simulated Author Two",
                        "abstract": "This is a simulated abstract generated by the LLM, demonstrating its ability to extract key information from the input text. It covers the main points of the paper concisely.",
                        "abstract_summary": "Simulated short summary of the abstract.",
                    }
                )
            elif "summarize" in prompt.lower():
                return "This is a simulated summary generated by the LLM based on the input text provided."
            else:
                return "Simulated LLM response: Hello, this is a placeholder response."
        else:
            # --- REAL LLM API CALL WOULD GO HERE ---
            # Example for OpenAI:
            # try:
            #     response = self.client.chat.completions.create(
            #         model=self.model_name,
            #         messages=[
            #             {"role": "system", "content": "You are a helpful assistant."},
            #             {"role": "user", "content": prompt}
            #         ],
            #         max_tokens=max_tokens,
            #         temperature=temperature,
            #         response_format={"type": "json_object"} if "json" in prompt.lower() else {"type": "text"}
            #     )
            #     return response.choices[0].message.content
            # except Exception as e:
            #     logger.error(f"Error calling LLM API: {e}")
            #     return None
            logger.warning(
                "LLM API key is set, but actual API call is not implemented yet in LLMInterface. Simulating response."
            )
            return self.generate_text(prompt, max_tokens, temperature)  # Fallback to simulation

    def generate_json(
        self, prompt: str, schema: Optional[Dict] = None, max_tokens: int = 1000, temperature: float = 0.7
    ) -> Optional[Dict[str, Any]]:
        """
        Generates a JSON response from the LLM based on the prompt and an optional schema.
        """
        raw_response = self.generate_text(prompt, max_tokens, temperature)
        if raw_response:
            try:
                # Attempt to parse as JSON. LLM might return non-JSON if not prompted correctly.
                # It's good practice to try to extract valid JSON from potentially malformed output
                # For now, we assume LLM adheres to JSON format if requested.
                json_start = raw_response.find("{")
                json_end = raw_response.rfind("}")
                if json_start != -1 and json_end != -1 and json_end > json_start:
                    json_string = raw_response[json_start : json_end + 1]
                    return json.loads(json_string)
                else:
                    logger.warning(f"LLM response did not contain valid JSON: {raw_response[:200]}...")
                    return None
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse LLM response as JSON: {e}. Raw response: {raw_response[:200]}...")
                return None
        return None
